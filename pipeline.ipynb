{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first way of creating a pipeline - create_from_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_First_Dist():\n",
    "    \n",
    "  from google.cloud import storage\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import random\n",
    "\n",
    "  SIZE_OF_ARRAY = 1000\n",
    "  first_dist = np.zeros(SIZE_OF_ARRAY)\n",
    "\n",
    "  mu_1 = 2\n",
    "  sigma_1 = 0.5\n",
    "\n",
    "  for i in range(SIZE_OF_ARRAY):\n",
    "       first_dist[i] = random.normalvariate(mu_1, sigma_1)   \n",
    "        \n",
    "  df_first_dist = pd.DataFrame(first_dist, columns = ['Column_A'])\n",
    "    \n",
    "  client = storage.Client()\n",
    "    \n",
    "  bucket = client.bucket(\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  bucket.blob('upload_test/first_dist4.csv').upload_from_string(df_first_dist.to_csv(), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Second_Dist():\n",
    "    \n",
    "  from google.cloud import storage\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import random\n",
    "\n",
    "  SIZE_OF_ARRAY = 1000  \n",
    "  second_dist = np.zeros(SIZE_OF_ARRAY)\n",
    "    \n",
    "  mu_2 = 4\n",
    "  sigma_2 = 0.5\n",
    "\n",
    "  for i in range(SIZE_OF_ARRAY):\n",
    "       second_dist[i] = random.normalvariate(mu_2, sigma_2)  \n",
    "        \n",
    "  df_second_dist = pd.DataFrame(second_dist, columns = ['Column_A'])\n",
    "    \n",
    "  client = storage.Client()\n",
    "    \n",
    "  bucket = client.bucket(\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  bucket.blob('upload_test/second_dist4.csv').upload_from_string(df_second_dist.to_csv(), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Third_Dist():\n",
    "    \n",
    "  from google.cloud import storage\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import random\n",
    "  \n",
    "\n",
    "  SIZE_OF_ARRAY = 1000  \n",
    "  third_dist = np.zeros(SIZE_OF_ARRAY)\n",
    "    \n",
    "  mu_3 = 4\n",
    "  sigma_3 = 0.5\n",
    "\n",
    "  for i in range(SIZE_OF_ARRAY):\n",
    "       third_dist[i] = random.normalvariate(mu_3, sigma_3)  \n",
    "        \n",
    "  df_third_dist = pd.DataFrame(third_dist, columns = ['Column_A'])\n",
    "    \n",
    "  client = storage.Client()\n",
    "    \n",
    "  bucket = client.bucket(\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  bucket.blob('upload_test/third_dist4.csv').upload_from_string(df_third_dist.to_csv(), 'text/csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Fourth_Dist():\n",
    "        \n",
    "    \n",
    "  from google.cloud import storage\n",
    "  import numpy as np\n",
    "  import pandas as pd\n",
    "  import random\n",
    "  from fs_gcsfs import GCSFS\n",
    "  import gcsfs\n",
    "  \n",
    "  #gcsfs = GCSFS(bucket_name=\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  #with gcsfs.open(\"gcs://my-3rd-project-363814-kubeflowpipelines-default/upload_test/first_dist3.csv\", \"rb\") as gcs_file:\n",
    "   #pass\n",
    "\n",
    "\n",
    "  #df = pd.read_csv(\"gcs://my-3rd-project-363814-kubeflowpipelines-default/upload_test/first_dist2.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  fs = gcsfs.GCSFileSystem(project='my-3rd-project-363814')\n",
    "  with fs.open('my-3rd-project-363814-kubeflowpipelines-default/upload_test/first_dist4.csv') as f:\n",
    "        df_first_dist = pd.read_csv(f)    \n",
    "  with fs.open('my-3rd-project-363814-kubeflowpipelines-default/upload_test/second_dist4.csv') as f:\n",
    "        df_second_dist = pd.read_csv(f)\n",
    "        \n",
    "  #client = storage.Client()\n",
    "    \n",
    "  #bucket = client.bucket(\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  #bucket.blob('upload_test/first_dist2.csv').download_to_string(pd.read_csv(), 'text/csv')\n",
    "    \n",
    "    \n",
    "  '''  \n",
    "  blob = bucket.blob('my.csv')\n",
    "\n",
    "  path = \"gs://my-3rd-project-363814-kubeflowpipelines-default/upload_test/second_dist2.csv\"\n",
    "  df_second_dist = pd.read_csv(path)\n",
    "\n",
    "  path = \"gs://my-3rd-project-363814-kubeflowpipelines-default/upload_test/first_dist2.csv\"\n",
    "  df_first_dist = pd.read_csv(path)'''\n",
    "        \n",
    "  SIZE_OF_ARRAY = 1000  \n",
    "  fourth_dist = np.zeros(SIZE_OF_ARRAY)\n",
    "    \n",
    "    \n",
    "  fourth_dist = df_first_dist['Column_A'].to_numpy() + df_second_dist['Column_A'].to_numpy()\n",
    "\n",
    "  df_fourth_dist = pd.DataFrame(fourth_dist, columns = ['Column_A'])\n",
    "\n",
    "  #with fs.open('my-3rd-project-363814-kubeflowpipelines-default/upload_test/fourth_dist3.csv') as f:\n",
    "       #df_fourth_dist.to_csv(f)\n",
    "  client = storage.Client()   \n",
    "  bucket = client.bucket(\"my-3rd-project-363814-kubeflowpipelines-default\")\n",
    "  bucket.blob('upload_test/fourth_dist4.csv').upload_from_string(df_fourth_dist.to_csv(), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_preprocess_first_dist = kfp.components.create_component_from_func(\n",
    "    func=Generate_First_Dist,\n",
    "    output_component_file='component_first_dist.yaml', # This is optional. It saves the component spec for future use.\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas==1.1.4','google-cloud-storage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_preprocess_second_dist = kfp.components.create_component_from_func(\n",
    "    func=Generate_Second_Dist,\n",
    "    output_component_file='component_second_dist.yaml', # This is optional. It saves the component spec for future use.\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas==1.1.4','google-cloud-storage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_preprocess_third_dist = kfp.components.create_component_from_func(\n",
    "    func=Generate_Third_Dist,\n",
    "    output_component_file='component_third_dist.yaml', # This is optional. It saves the component spec for future use.\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas==1.1.4','google-cloud-storage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_step_data_preprocess_fourth_dist = kfp.components.create_component_from_func(\n",
    "    func=Generate_Fourth_Dist,\n",
    "    output_component_file='component_fourth_dist.yaml', # This is optional. It saves the component spec for future use.\n",
    "    base_image='python:3.7',\n",
    "    packages_to_install=['pandas==1.1.4','google-cloud-storage','gcsfs','fs_gcsfs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline and create a task from a component:\n",
    "def my_pipeline():\n",
    "  data_preprocess_task_1 = create_step_data_preprocess_first_dist()\n",
    "  data_preprocess_task_2 = create_step_data_preprocess_second_dist()\n",
    "  data_preprocess_task_3 = create_step_data_preprocess_third_dist().after(data_preprocess_task_1,data_preprocess_task_2)\n",
    "  data_preprocess_task_4 = create_step_data_preprocess_fourth_dist().after(data_preprocess_task_1,data_preprocess_task_2)\n",
    "  # The outputs of the merge_csv_task can be referenced using the\n",
    "  # merge_csv_task.outputs dictionary: merge_csv_task.outputs['output_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host='https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/experiments/details/7ef83054-111f-46d8-b9b1-259cd5eed402\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/runs/details/620d1b13-b325-46d8-a08b-c9afe1605a74\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=620d1b13-b325-46d8-a08b-c9afe1605a74)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_func(my_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Second Way of building components, more professional, created from docker immages\n",
    "\n",
    "''' \n",
    "Docker images are built on a git-push to remote repo in GitHub, a trigger automatically builds image from python code using a \n",
    "Dockerfile and cloud_build.yaml, as kubeflow pipeline is an emmissary executor so command to be given in containerOp object\n",
    "declaration, not in Dockerfile\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "#from kubernetes.client.models import V1EnvVar, V1SecretKeySelector\n",
    "\n",
    "@dsl.pipeline(\n",
    "          name='foo',\n",
    "          description='hello world')\n",
    "def foo_pipeline(tag: str, pull_image_policy: str):\n",
    "        # any attributes can be parameterized (both serialized string or actual PipelineParam)\n",
    "        op = dsl.ContainerOp(name='First Distribution',\n",
    "                            image='gcr.io/my-3rd-project-363814/distribution3:latest',\n",
    "                            command = ['sh', '-c'], #command to execute after entering into container\n",
    "                            arguments=['python myprogram.py','echo \"Hello World\"'], #command to execute after entering into container\n",
    "        )\n",
    "        # set `imagePullPolicy` property for `container` with `PipelineParam`\n",
    "        #op.container.set_image_pull_policy(pull_image_policy)\n",
    "        # add sidecar with parameterized image tag\n",
    "        # sidecar follows the argo sidecar swagger spec\n",
    "        #op.add_sidecar(dsl.Sidecar('redis', 'redis:%s' % tag).set_image_pull_policy('Always'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "client = kfp.Client(host='https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way of running a pipeline, compile, create yaml and upload from user interface\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=foo_pipeline,\n",
    "    package_path='foo_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/experiments/details/7ef83054-111f-46d8-b9b1-259cd5eed402\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/runs/details/f0486a0f-1eb6-419e-a3d4-bd1e9276c7fc\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=f0486a0f-1eb6-419e-a3d4-bd1e9276c7fc)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_func(foo_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "#from kubernetes.client.models import V1EnvVar, V1SecretKeySelector\n",
    "\n",
    "@dsl.pipeline(\n",
    "          name='python_package_demonstrator',\n",
    "          description='hello world')\n",
    "def gcp_pipeline(tag: str, pull_image_policy: str):\n",
    "        # any attributes can be parameterized (both serialized string or actual PipelineParam)\n",
    "        op = dsl.ContainerOp(name='Normal Distribution',\n",
    "                            image='gcr.io/my-3rd-project-363814/normal_dist:latest',\n",
    "                            command = ['sh', '-c'], #command to execute after entering into container\n",
    "                            arguments=['python ./Python_Package_Modules_Concepts/Main_Program.py'], #command to execute after entering into container\n",
    "        )\n",
    "        # set `imagePullPolicy` property for `container` with `PipelineParam`\n",
    "        #op.container.set_image_pull_policy(pull_image_policy)\n",
    "        # add sidecar with parameterized image tag\n",
    "        # sidecar follows the argo sidecar swagger spec\n",
    "        #op.add_sidecar(dsl.Sidecar('redis', 'redis:%s' % tag).set_image_pull_policy('Always'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "client = kfp.Client(host='https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way of running a pipeline, compile, create yaml and upload from user interface\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=gcp_pipeline,\n",
    "    package_path='gcp_pipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/experiments/details/7ef83054-111f-46d8-b9b1-259cd5eed402\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://5e590293dda42c48-dot-asia-east1.pipelines.googleusercontent.com/#/runs/details/021077e3-3414-4a53-bfa2-67e89da77485\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=021077e3-3414-4a53-bfa2-67e89da77485)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_run_from_pipeline_func(gcp_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
